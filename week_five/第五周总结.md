## 第五周总结

### 首先是第五周的课程笔记，如下：
5.1 分布式缓存架构：架构原理与使用中的注意事项
缓存：原始数据的一个复制集，以便于访问，可以加快数据访问速度。
无处不在的缓存：CPU缓存，操作系统缓存，数据库缓存，JVM编译缓存，CDN缓存，代理和反向代理缓存，前端缓存，应用程序缓存，分布式对象缓存
缓存存储数据：大部分case都是哈希表
缓存关键指标：缓存命中率。（这里我个人感觉对于很大一部分公司来说，由于目前缓存其实没有想象的那么贵，所以这个命中率其实没有那么的重要，主要是可以实现一些业务就行）
影响缓存命中率的因素：缓存键集合的大小，缓存可使用内存空间的大小，缓存对象的生存时间。

5.2 分布式缓存架构：常见的缓存实现形式
代理缓存：部署在用户端，一般不在系统设计中考虑
反向代理：代理数据中心的代理服务器，可以缓存一部分的内容。是架构的重要组成部分，是数据中心的一部分。
多层反向代理服务器：有网页资源的地方都可以加一层反向代理服务器。
CDN：内容分发网络。由网络服务商提供，离用户很近。一般静态资源都会缓存在CDN中。CDN和运营商绑定，不同的运营商要分别部署，比如说移动的用户只能访问移动的CDN
通读缓存（CND，代理等）：如果存在客户端需要的资源就返回，不然就透传到服务端
旁路缓存（程序逻辑中的key，value）：客户端需要分别知道缓存和服务器的地址，客户端需要自己写缓存。
本地对象缓存：应用程序内存中的缓存。可以多线程共享，也可以多进程共享。
远程分布式对象缓存：单独一个集群用来缓存，通过RPC调用。比较方便线性伸缩。常用，如redis。
Memcached主要架构设计（share-nothing）：通过key计算集群中对应机器IP，每个key进入特定的机器，整体很容易进行线性伸缩。（从余数哈希算法看起来，伸缩扩容的时候应该要进行一定的数据同步和预热才对）

5.3 分布式缓存架构：一致性哈希
一致性哈希插入新节点时，只是插入点周边的2个节点的key命中率会受影响。
通过虚拟节点的方式来解决一致性哈希导致的数据偏移问题。一个机器对应多个虚拟节点，这些节点是相互交错随机散落的，新增加的服务器也会散落大量的虚拟节点到原有的哈希环中，会影响原来所有的物理节点。
技术栈各个层次的缓存：客户端缓存 -> HTTP反向代理/CDN -> Web应用服务器（本地，分布式） -> HTTP反向代理 -> Web服务服务器（本地，分布式） -> 主数据库存储。所节约的资源大约依次是 100% -> 98 -> 75% -> 66% -> 50% -> 0%。
缓存是优化性能的大杀器，要尽量多的使用，但不要滥用。一次写入至少读2次以上才有意义。
数据有热点才有缓存的价值，大部分场景，80%的请求集中在20%的数据。
缓存设置生效时间，比如说3分钟，卖家编辑商品要3分钟才去数据库重新加载，应用要能容忍这一段时间的不一致。可以通过主动通知的机制提高一致性，不过这样系统开销会高一点。
为了防止底层系统崩溃，需要warm up缓存。
不存在的数据也缓存一下，防止被攻击时缓存穿透导致底层崩溃。
Memcached：share nothing； redis：既支持share nothing，又支持原生集群，其中原生集群会分享桶的配置，以及新机器加入时会重新分配桶，做到类似于一致性哈希那样，使得大部分key还是能命中的效果

5.4 消息队列：如何避免系统故障传递？
缓存主要是用来优化读性能，写数据性能优化可以用消息队列异步来实现。
消息队列类型：点对点模型；发布订阅模型（一次生产，多次消费）
消息队列的好处：异步实现，提升性能；削峰填谷；失败隔离和自我修复；解耦；事件驱动架构EDA->降低请求/响应耦合表面积
一个取巧的MQ产品比较方法，Google搜索比较结果数。

5.5 负载均衡架构：如何用十行代码写一个负载均衡服务器？
用户请求进来以后先到负载均衡服务器，然后转发给各个应用服务器
HTTP重定向负载均衡：负载均衡服务器只计算重定向地址。
	优点：实现和部署简单
	缺点：效率低，安全性问题（会暴露内网服务器地址）
DNS负载均衡：同一个域名解析成不同的IP地址，从而实现负载均衡
	优点：不需要自己实现，比重定向更简单
	缺点：安全性问题，这一点和HTTP重定向是一样的。（一般大型网络利用DNS负载均衡把请求平摊到他们内部的负载均衡服务器）
反向代理负载均衡：反向代理服务器在把请求发给服务器集群之前，可以先做一次负载均衡。（一般都是用在比较小的集群）
	缺点：反向代理是HTTP请求，要做HTTP层的包装，性能比较差，所以规模大的一般不用。
IP负载均衡：直接改IP地址转发给内网服务器，拿到返回后再改IP返回给用户。
	优点：IP层就解决问题了，没有上层协议的消耗，性能整体更好。
	缺点：返回的包可能会很大，网卡可能会成为瓶颈
数据链路层负载均衡：负载均衡和应用服务器的虚拟IP是同一个，通过修改目标Mac地址来实现负载均衡
	优点：由于源Ip和目标Ip没有经过修改，所以响应直接由应用服务器响应给用户，也就是说，返回不经过负载均衡服务器，降低了负载均衡服务器的压力，提高了性能。
负载均衡算法：轮询&加权轮询，随机&加权随机，最少连接（真正意义上的负载均衡，但比较复杂，计数容易错，一般来说不用），源地址散列（主要是实现同一个来源的请求总在同一台服务器处理，会话黏滞，实践中也不常见）
负载均衡下的session管理：
	session复制：集群之间相互复制session，比较简单，但是集群机器多时消耗资源，不可伸缩
	源地址散列：实践中也很少使用，因为服务器绑定的话不符合高可用，发版也会导致session丢失。
	通过cookie记录session：利用浏览器cookie，比较简单高效，实践中也有应用。但是有时候cookie会被禁用，cookie中能存的东西也不多。
	使用session服务器来专门记录用户状态：最常见。应用服务器无状态，share nothing，很容易伸缩，非常高效。

### 个人总结
这一节主要讲了分布式缓存，消息队列，以及负载均衡。这些中间件在以往的工作中用的很多，但一直没有仔细去研究过它们的一些核心的，重要的原理，或是架构等等。本周的课在一定程度上扫了扫知识盲区，同时，在当前工程能力的基础上，这些东西看下来已经显得并不陌生，并且很好理解，甚至自己能实现一些核心的东西了。这大概算是大量的福报带来的一点点好处吧。。。